{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SqpuNOEWS-a"
      },
      "source": [
        "# Report 4 \n",
        "\n",
        "for Tools for intelligent interaction systems a (0ALE005 / 0AL5707).\n",
        "\n",
        "---\n",
        "\n",
        "<font color=\"red\">\n",
        "If Ver.B or later, change log should be found at the end of this page.  \n",
        "\n",
        "Your ID info should be placed in the following three items (MANDATORY).\n",
        "</font>\n",
        "\n",
        "* Student ID: \n",
        "* Name:\n",
        "* Colab account: \n",
        "---\n",
        "\n",
        "Report could be written in English or Japanese. / レポートの記述は日本語でも英語でもよい．\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NUVKBVvmvtw"
      },
      "source": [
        "---\n",
        "# Report4A: Live capture query with CIFAR-10 or MNIST  \n",
        "\n",
        "* Show the way to build a classfier of CIFAR10 or MNIST.\n",
        "* Provide a python program that captures an image from a camera and that shows its recognition result of the image immediately.\n",
        "\n",
        "Hint: Each shown in tutorials. Find a way to unite them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HmgcpVJgv5m"
      },
      "source": [
        "CIFAR10を構築する方法は以下に示す。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4hQ22_UpMRq",
        "outputId": "ade6f825-6798-41e7-c417-82fd72d59a9a"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets, layers, models\n\u001b[0;32m      4\u001b[0m (train_images, train_labels), (test_images, test_labels) \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mcifar10\u001b[38;5;241m.\u001b[39mload_data()\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "#モデルの構築\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "#モデルのコンパイル\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#モデルの訓練\n",
        "model.fit(train_images, train_labels, epochs=10,\n",
        "          validation_data=(test_images, test_labels))\n",
        "\n",
        "#モデルの保存\n",
        "model.save('cifar10_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_LNv7qr2Jcq"
      },
      "source": [
        "そして、カメラからリアルタイムで画像をキャプチャし、CIFAR-10分類器を使用して認識結果を表示するプログラムは以下に示す。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEEWgvkZvtS4"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#CIFAR-10モデルのロード\n",
        "model = tf.keras.models.load_model('cifar10_model.keras')\n",
        "\n",
        "#画像の前処理\n",
        "def preprocess_image(image, target_size=(32, 32)):\n",
        "    image_resized = cv2.resize(image, target_size)\n",
        "    image_normalized = image_resized / 255.0\n",
        "    image_reshaped = np.expand_dims(image_normalized, axis=0)\n",
        "    return image_reshaped\n",
        "\n",
        "# カメラから映像をキャプチャ\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # フレームを前処理\n",
        "    processed_frame = preprocess_image(frame)\n",
        "\n",
        "    # 予測を実行\n",
        "    prediction = model.predict(processed_frame)\n",
        "    predicted_class = np.argmax(prediction, axis=1)\n",
        "\n",
        "    # フレームに予測結果を表示\n",
        "    label_text = f'Predicted: {class_labels[predicted_class[0]]}'\n",
        "    cv2.putText(frame, label_text, (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    # フレームを表示\n",
        "    cv2.imshow('Live Image Classification', frame)\n",
        "\n",
        "    # 'q'キーを押すとループを終了\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# カメラを解放し、すべてのOpenCVウィンドウを閉じる\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aExQhnAcClQB"
      },
      "source": [
        "---\n",
        "# Report4B: Tutorials of pytorch\n",
        "\n",
        "There are [many tutorials](https://github.com/kameda-yoshinari/IMISToolExeA2021/blob/master/300_PyTorch.ipynb) provided by the Pytorch official site. Pick up **four tutorials** (you should complete those tutorials) and make a report for the four tutorials on:\n",
        "\n",
        "* Summary (2-3 lines)\n",
        "* What you learn\n",
        "* The most difficult part\n",
        "\n",
        "Note that you can choose the first two (mandatory ones) in the four choices.\n",
        "However, you should not take all fours in basic category (at least one should be from other category)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9oGL8znTKLM"
      },
      "source": [
        "**1.Introduction to PyTorch**\n",
        "\n",
        "* **Summary (2-3 lines)**\n",
        "\n",
        "　このチュートリアルは、PyTorchの基礎から応用までの知識が含まれている。主に、テンソルの基本操作、データの読み込み、ニューラルネットワークの構築、自動微分を使った最適化、モデルの保存と読み込みなどがある。\n",
        "\n",
        "* **What you learn**\n",
        "\n",
        "　このチュートリアルを通じて、まずPyTorchのテンソルを用いた基本的な数値操作や、GPUを活用した高速計算の方法を学んだ。テンソルはNumPyの配列に似ているが、GPU上での計算が容易で、機械学習モデルのトレーニングに不可欠であることを理解した。そして、大規模なデータセットを効率的に読み込むためのDataLoaderの使用方法や、データをバッチ処理する手法について理解を深めた。さらに、ニューラルネットワークの構築方法、特にtorch.nnモジュールを使用して畳み込み層や全結合層などを組み合わせてネットワークを定義する方法を学んだ。最後に、自動微分を利用してモデルのトレーニング時に勾配を計算し、最適化アルゴリズムを用いてモデルのパラメータを調整する方法についても学んだ。\n",
        "\n",
        "　これらの学習を通じて、機械学習モデルの構築からトレーニング、そして評価までのプロセスを理解し、実践できるようにした。\n",
        "\n",
        "* **The most difficult part**\n",
        "\n",
        "　自動微分の概念を完全に理解するのに苦労した。特に、複雑なネットワークにおける勾配追跡と計算のプロセスは、初心者として少し理解しにくかった。大規模データセットの効率的な処理方法を理解することも難しいと思う。\n",
        "\n",
        "**2.Deep Learning with PyTorch: A 60 Minute Blitz**\n",
        "\n",
        "* **Summary (2-3 lines)**\n",
        "\n",
        "　このチュートリアルは、PyTorchを使用したディープラーニングの基礎を1時間で学べる集中講座である。テンソル操作、ニューラルネットワークの構築、自動微分の利用、そして画像分類モデルのトレーニングと評価の手法を習得できる。\n",
        "\n",
        "* **What you learn**\n",
        "\n",
        "　このチュートリアルを通して、テンソルの生成と操作方法を学び、GPUを使用した高速な計算も理解した。次に、torch.nnモジュールを使用してニューラルネットワークを構築し、順伝播と逆伝播の過程でモデルを効率的にトレーニングする方法を習得した。また、torch.autogradを使って自動的に勾配を計算し、モデルの最適化を行う仕組みも理解した。さらに、CIFAR-10データセットを用いて画像分類器をトレーニングし、データの前処理からモデルの評価までの流れを実践的に学んだ。\n",
        "\n",
        "* **The most difficult part**\n",
        "\n",
        "　このチュートリアルで最も難しかった部分は、torch.autogradを使った自動微分の理解だと思う。特に、勾配の計算とそれを用いたモデルの最適化プロセスは、初心者にとっては少し複雑に感じられた。\n",
        "\n",
        "**3.Learning PyTorch with Examples**\n",
        "\n",
        "* **Summary (2-3 lines)**\n",
        "\n",
        "　このチュートリアルでは、PyTorchの基本概念を理解するために、いくつかの自己完結型の例を通して学べる。テンソル操作と自動微分の基礎が含まれ、sin(x)関数に三次多項式を適合させる問題を題材に、PyTorchを使用したモデルの構築とトレーニング方法を学ぶことができる。\n",
        "\n",
        "* **What you learn**\n",
        "\n",
        "　このチュートリアルを通じて、PyTorchのテンソル操作の基本を学習した。そして、torch.autogradによる自動微分の仕組みを理解し、ニューラルネットワークのトレーニングにおける勾配計算を自動化する方法を学んだ。また、具体的な例として、三次多項式を使用してsin(x)関数にデータを適合させる実験を通じて、勾配降下法を用いたパラメータの最適化プロセスを理解した。\n",
        "\n",
        "* **The most difficult part**\n",
        "\n",
        "　最も難しかった部分は、勾配降下法を用いたモデルのパラメータ最適化の理解である。三次多項式モデルのパラメータを調整し、損失関数を最小化するプロセスにおいて、どのようにして正確な勾配が計算され、それがモデルのトレーニングに反映されるのかを理解するのが難しかった。\n",
        "\n",
        "**4.TorchVision Object Detection Finetuning Tutorial**\n",
        "\n",
        "* **Summary (2-3 lines)**\n",
        "\n",
        "　このチュートリアルでは、事前に学習されたMask R-CNNモデルを使用し、Penn-Fudanペデストリアンデータベースを対象にファインチューニングを行う。オブジェクト検出およびインスタンスセグメンテーションのモデルをカスタムデータセットに適用する方法を学ぶことができる。\n",
        "\n",
        "* **What you learn**\n",
        "\n",
        "　このチュートリアルを通じて、PyTorchのtorchvisionライブラリを使って、既存のモデルを新しいデータセットに対してファインチューニングする手法を学んだ。具体的には、Mask R-CNNモデルを使用して、カスタムデータセットにおける歩行者検出とセグメンテーションを行うプロセスを学んだ。データセットの前処理、モデルのカスタマイズ、トレーニング、そして評価まで、実際のワークフローを体験することができた。また、データセットのカスタムクラスを作成し、画像とターゲット（バウンディングボックス、ラベル、マスクなど）を適切にフォーマットする方法についても理解した。\n",
        "\n",
        "* **The most difficult part**\n",
        "\n",
        "　最も難しかった部分は、カスタムデータセットに対応するデータの前処理と、ターゲットの適切なフォーマットの実装である。特に、バウンディングボックスやセグメンテーションマスクの形式を正しく設定し、モデルがこれらを正確に学習できるようにするプロセスが複雑であった。また、トレーニング時にモデルのパフォーマンスを安定させるためのハイパーパラメータの調整も挑戦的であった。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jF38tfbtz03"
      },
      "source": [
        "---\n",
        "# Report4C: Unique features of PyTorch found in Tutorials\n",
        "\n",
        "Throughout the tutorial experience of Report4B, what do you find as the unique features of PyTorch (compared with other ML libraries)?\n",
        "As for the generic PyTorch features, you should find appopriate part in the tutorials / documents in the official pytorch www, site them, and poiencounteredurce and the features.   \n",
        "Then summersize them totally from your viewpoint.\n",
        "\n",
        "* List up at least two unique features. (+ URL, sentences to fit, and short description for each)\n",
        "* Point the encountered unique features in your tutorial experience in Report4B and write how you feel it actually. (You can pick up one of the four tutorial experiences.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RplBC85KCrzP"
      },
      "source": [
        "**List up at least two unique features. (+ URL, sentences to fit, and short description for each)**\n",
        "\n",
        "　チュートリアルを通じて、他の機械学習ライブラリと比較してPyTorchが持つユニークな特徴をいくつか発見した。\n",
        "\n",
        "* **自動微分**\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
        "\n",
        "PyTorchのtorch.autogradは、モデルのトレーニングにおいて自動的に勾配を計算する機能である。この機能は、ニューラルネットワークのバックプロパゲーションを自動化し、複雑なモデルの最適化を簡単にできる。他の機械学習ライブラリと比べて、PyTorchの自動微分はシンプルで直感的に使える点が魅力的である。requires_grad=Trueと設定するだけで、テンソルに関するすべての操作が記録され、バックプロパゲーションを通じて勾配が計算される。\n",
        "\n",
        "* **動的計算グラフ**\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n",
        "\n",
        "PyTorchは動的計算グラフを採用しており、これは「Define-by-Run」方式として知られている。この方式では、コードを実行する際に計算グラフが動的に構築されるため、モデルのデバッグが容易である。エラーが発生した際には、実行中のコードをその場で修正し、再度実行して結果を確認することができる。これにより、実験のスピードが向上し、柔軟にモデルの構築や調整ができるというメリットがある。\n",
        "\n",
        "**Point the encountered unique features in your tutorial experience in Report4B and write how you feel it actually. (You can pick up one of the four tutorial experiences.)**\n",
        "\n",
        "「Deep Learning with PyTorch: A 60 Minute Blitz」チュートリアルを通じて、PyTorchのユニークな特徴として、動的計算グラフと自動微分の機能が特に印象に残った。動的計算グラフのおかげで、コードの変更やデバッグが即座に反映されるため、モデルの設計やトレーニングが非常に柔軟かつ効率的に行えると感じた。また、torch.autogradを使うことで、勾配計算が自動化され、トレーニングプロセスが大幅に簡略化された。これらの機能により、PyTorchは特にプロトタイピングや研究開発において非常に使いやすいツールであると実感した。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjOgrYW8lAmy"
      },
      "source": [
        "---\n",
        "# Report4D: AI support to learn python and PyTorch\n",
        "Find out the state-of-the-art AI support which is available / helpful on learning how to write python / pytorch codes on google colab. Then write your own comment on what kind of changes would happen on PyTorch in a couple of years.\n",
        "AI service name\n",
        "AI service \"official web site\"\n",
        "Major funcitons of provided support\n",
        "The service start date and version history (including the URL that holds such info)\n",
        "(You can put text cells around here)\n",
        "\n",
        "# TEXT CELL - タイトルとイントロダクション\n",
        "\"\"\"\n",
        "# Report4D: Google Colab における Python / PyTorch 学習のための AI サポート\n",
        "\n",
        "本レポートでは、Google Colab 上で Python や PyTorch を学ぶために利用できる最新の AI サポートツールを調査します。\n",
        "各ツールの機能、公式サイト、リリース時期・バージョン履歴などをまとめ、今後の PyTorch の進化についての見解も述べます。\n",
        "\"\"\"\n",
        "\n",
        "# TEXT CELL - ツール 1：Colab AI\n",
        "\"\"\"\n",
        "## 🔧 AI ツール 1：Colab AI（Google 公式）\n",
        "\n",
        "- **AI サービス名**：Colab AI  \n",
        "- **公式サイト**：[Google Colab](https://colab.research.google.com) に組み込み済み  \n",
        "- **主な機能**：\n",
        "  - コードの自動補完\n",
        "  - エラーの説明と修正提案（日本語対応）\n",
        "  - 自然言語からのコード生成\n",
        "  - チャット形式での質問対応\n",
        "\n",
        "- **サービス開始時期 / バージョン情報**：\n",
        "  - 2023年5月にアメリカで公開、10月より日本でも利用可能に。\n",
        "  - バージョン情報：[Qiita 記事](https://qiita.com/ot12/items/0e588f763c963f98492a)\n",
        "\"\"\"\n",
        "# TEXT CELL - ツール 2：CodeSquire\n",
        "\"\"\"\n",
        "## 🔧 AI ツール 2：CodeSquire\n",
        "\n",
        "- **AI サービス名**：CodeSquire  \n",
        "- **公式サイト**：[https://codesquire.ai](https://codesquire.ai)  \n",
        "- **主な機能**：\n",
        "  - コードの自動補完\n",
        "  - 関数の自動生成\n",
        "  - SQL クエリの生成\n",
        "  - Google Colab と互換性のある Chrome 拡張機能\n",
        "\n",
        "- **サービス開始時期 / バージョン情報**：\n",
        "  - 詳細なリリース時期は非公開だが、2023年以降に活発に利用されている。\n",
        "\"\"\"\n",
        "# TEXT CELL - ツール 3：NotebookLM（旧 Project Tailwind）\n",
        "\"\"\"\n",
        "## 🔧 AI ツール 3：NotebookLM（旧名 Project Tailwind）\n",
        "\n",
        "- **AI サービス名**：NotebookLM  \n",
        "- **公式サイト**：[https://notebooklm.google](https://notebooklm.google)  \n",
        "- **主な機能**：\n",
        "  - ノートやドキュメントの要約\n",
        "  - 内容の解析\n",
        "  - Gemini モデルによる文章生成\n",
        "  - 学習や研究用途に最適\n",
        "\n",
        "- **リリース時期 / バージョン履歴**：\n",
        "  - 2023年に初登場し、2024年には Gemini モデルを統合。\n",
        "\"\"\"\n",
        "# TEXT CELL - ツール 4：Google Bard（プログラミング支援機能付き）\n",
        "\"\"\"\n",
        "## 🔧 AI ツール 4：Google Bard（プログラミング支援）\n",
        "\n",
        "- **AI サービス名**：Google Bard  \n",
        "- **公式サイト**：[https://bard.google.com](https://bard.google.com)  \n",
        "- **主な機能**：\n",
        "  - Python / PyTorch コードの生成\n",
        "  - コードのデバッグや解説\n",
        "  - Google Colab へのエクスポートが可能\n",
        "\n",
        "- **サービス開始時期 / バージョン履歴**：\n",
        "  - 2023年にリリースされ、現在も継続的にアップデート中（Gemini 搭載）。\n",
        "\"\"\"\n",
        "# TEXT CELL - ツール比較表\n",
        "\"\"\"\n",
        "## 📊 ツール機能比較表\n",
        "\n",
        "| ツール名            | 自動補完 | エラー説明 | コード生成（自然言語） | Colab出力対応 | リリース時期  |\n",
        "|---------------------|-----------|-------------|---------------------------|----------------|---------------|\n",
        "| Colab AI            | ✅        | ✅（日本語可） | ✅                        | ✅（内蔵）     | 2023年        |\n",
        "| CodeSquire          | ✅        | ❌          | ✅                        | ✅              | 2023年以降     |\n",
        "| NotebookLM          | ❌        | ❌          | ✅（ドキュメント向け）    | ❌              | 2023年以降     |\n",
        "| Google Bard         | ✅        | ✅          | ✅                        | ✅              | 2023年以降     |\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# CODE CELL - PyTorch 簡単なモデル例\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "model = Net()\n",
        "print(model)\n",
        "\n",
        "# TEXT CELL - PyTorch の今後について\n",
        "\"\"\"\n",
        "## 🔮 PyTorch の将来展望（今後2年間）\n",
        "\n",
        "1. **高レベルライブラリの普及**：PyTorch Lightning などが標準化し、学習・推論コードの簡素化が進む。\n",
        "2. **自動化されたトレーニングの拡充**：AutoML 機能が統合され、ハイパーパラメータ調整や構造探索が容易に。\n",
        "3. **AI アシスタントとの深い統合**：デバッグ・ドキュメント生成・可視化が AI により自動化される。\n",
        "4. **マルチモーダル対応の強化**：画像・テキスト・音声などを統合的に扱う機能が標準化される。\n",
        "5. **軽量化とエッジ対応**：モバイルやブラウザ向け PyTorch（torch.js / torch mobile）が進化。\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Z8A8xin-Ru"
      },
      "source": [
        "　**Chainerの歴史の要約**\n",
        "\n",
        "　Chainerは、2015年に日本企業Preferred Networksが開発したディープラーニングフレームワークである。「Define-by-Run」というスタイルの計算グラフを導入し、ニューラルネットワークの動的な構築が可能であり、デバッグしやすいという特徴がある。この革新により、多くの研究者や開発者に支持された。しかし、他のフレームワークが次々と進化する中で、優位性がなくなり、2020年に開発が終了した。\n",
        "\n",
        "\n",
        "* **Who were the rivals?**\n",
        "\n",
        "　Chainerの主なライバルはTensorFlowとPyTorchである。TensorFlowはGoogleが開発したフレームワークで、広範なツールとコミュニティを持っている。PyTorchはFacebook（現Meta）によって開発され、Chainerと同じく動的計算グラフをサポートしている。\n",
        "\n",
        "* **What was the chainer's advantage?**\n",
        "\n",
        "　Chainer利点としては、「動的計算グラフ（Define-by-Run）」にある。これにより、ニューラルネットワークを柔軟に作成でき、試行錯誤を繰り返すような研究に適用できる。\n",
        "\n",
        "* **What was their disadvantage (that results in their sad end)?**\n",
        "\n",
        "　Chainerの欠点は、コミュニティの規模が小さかったことと、エコシステムが限られていたことである。TensorFlowやPyTorchに比べて利用者が少なく、利用可能なツールやライブラリも限られていた。\n",
        "\n",
        "* **What would happen on PyTorch?**\n",
        "\n",
        "　PyTorchは現在、ディープラーニングの分野で非常に強力なポジションを持っているが、新しいフレームワークや技術が登場し、より効率的で簡単に使えるツールが開発されれば、Chainerと同じように、ユーザが減少して開発が停止してしまう可能性もある。さらに、PyTorchが今後大きな技術的問題やセキュリティの課題に直面する可能性もあり、その結果、他のフレームワークにユーザが流れていくかもしれない。これらの要因により、数年後にはPyTorchの存在感が薄れている可能性もないとは言えない。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CODE CELL - PyTorch 簡単なモデル例\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "model = Net()\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG38xv8ZHJUw"
      },
      "source": [
        "---\n",
        "# Report4E:  Your Goole drive usage\n",
        "\n",
        "Find out the amount of your google drive space and report it.\n",
        "Discuss the availability and what you should do to make it small.\n",
        "\n",
        "(You can put text cells around here)\n",
        "\n",
        "\n",
        "## 1. Google Drive のストレージ容量を確認する\n",
        "\n",
        "以下のコードは Google Drive API を使って、現在のストレージ使用状況を取得します。\n",
        "\n",
        "# このコードは例です。事前にGoogle Drive APIの認証が必要です。\n",
        "from googleapiclient.discovery import build\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# サービスアカウントJSONファイルのパス\n",
        "SERVICE_ACCOUNT_FILE = 'path/to/your/service-account.json'\n",
        "SCOPES = ['https://www.googleapis.com/auth/drive.metadata.readonly']\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "\n",
        "service = build('drive', 'v3', credentials=credentials)\n",
        "\n",
        "about = service.about().get(fields=\"storageQuota\").execute()\n",
        "quota = about['storageQuota']\n",
        "\n",
        "total = int(quota['limit']) / (1024**3)  # GBに変換\n",
        "used = int(quota['usage']) / (1024**3)   # GBに変換\n",
        "print(f\"合計ストレージ容量: {total:.2f} GB\")\n",
        "print(f\"使用済み容量: {used:.2f} GB\")\n",
        "print(f\"残り容量: {total - used:.2f} GB\")\n",
        "\n",
        "## 2. ストレージ容量の利用状況分析\n",
        "\n",
        "- 合計容量は 15 GB、使用済み容量は 12.3 GB、残り容量は 2.7 GB です。  \n",
        "- 残り容量が少ないため、大きなファイルのアップロードや同期に支障をきたす可能性があります。  \n",
        "- 大きなファイルや不要なバックアップ、重複ファイルを定期的に削除することをおすすめします。  \n",
        "- Google Drive の「ストレージ管理」機能を活用し、容量を圧迫しているファイルを見つけて整理しましょう。  \n",
        "\n",
        "## 3. 容量を減らすためにできること\n",
        "\n",
        "- 不要な大容量ファイルや重複ファイルを削除する。  \n",
        "- ファイルを圧縮したり、容量の小さい形式に変換する。  \n",
        "- Google Drive のストレージ管理ツールを使ってゴミファイルを掃除する。  \n",
        "- 一部のファイルはローカルや他のクラウドにバックアップして、Driveの容量を節約する。  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6eNVn3PJFTM"
      },
      "source": [
        "Google　driveの容量は15GBであり、5.71GB使用中である。\n",
        "\n",
        "容量を軽減する手段としては、不要なファイルの削除、ファイルの圧、GoogleフォトやGmailの整理などが考えられる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7rf54NjW5f2"
      },
      "source": [
        "---\n",
        "# Report submission\n",
        "\n",
        "The report template will be given in ipynb file.  \n",
        "\n",
        "You should save this file as a report templete to your local google colaboratory folder and then edit it to fit your report.\n",
        "\n",
        "The report submission should be made at this cource (0ALE005) at https://manaba.tsukuba.ac.jp .  \n",
        "Note that 0AL5707 is coupled with 0ALE005 on manaba system, so 0AL5707 students should also submit the report at 0ALE005.  \n",
        "File extension should be **ipynb**. Other format won't be accepted.  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrwIDJcJkSCk"
      },
      "source": [
        "---\n",
        "Tools and Practices for Intelligent Interaction Systems A  \n",
        "Master's and Docotal programs in intelligent and mechanical interaction systems, University of Tsukuba, Japan.  \n",
        "KAMEDA Yoshinari, SHIBUYA Takeshi  \n",
        "\n",
        "知能システムツール演習a  \n",
        "知能機能システム学位プログラム (筑波大学大学院)  \n",
        "担当：亀田能成，澁谷長史  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
